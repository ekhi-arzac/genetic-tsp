{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic TSP\n",
    "Introduction: \n",
    "travelling salesman is a NP-hard problem, which means it is impossible to solve it in polynomial time. However, we can use genetic algorithm to find a good solution in a reasonable time. \n",
    "\n",
    "Genetic algorithm is a heuristic search algorithm inspired by the process of natural selection. It is based on the idea of evolution, where the fittest individuals are selected for reproduction in order to produce offspring of the next generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "We first need to setup our environment. If you are new to Python or Jupyter Notebooks, it is recommended to use cloud services like Google Colab, as it provides an already setup environment for you to work with. Otherwise, you need to install the following libraries on your local machine: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to import the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Matrix initialization, and solution representation\n",
    "We need to represent the problem in a way that the algorithm can understand. We will use a matrix to represent the distances between cities. We will also represent the solution as a list of cities.\n",
    "$$\n",
    "n \\equiv \\text{number of cities} \\quad n\\in\\mathbb{N}\\\\\n",
    "C_{i} \\equiv  i^{th} \\text { City} \\quad i\\in[0,n-1]\\\\\n",
    "$$\n",
    "\n",
    "The distance matrix $D$ can be defined as follows:\n",
    "$$\n",
    "D \\in \\mathbb{R}^{n\\times n} \\quad \\\\\n",
    "D_{ij} \\equiv \\text{Distance between city } C_{i} \\text{ and city } C_{j} \\quad i,j\\in[0,n-1]\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load distance matrix from a file\n",
    "def load_distance_matrix(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    n = len(lines)\n",
    "    d_matrix = np.zeros((n, n))\n",
    "    for i, line in enumerate(lines):\n",
    "        d_matrix[i] = list(map(float, line.split()))\n",
    "    return d_matrix\n",
    "\n",
    "# plot cost matrix as a heatmap\n",
    "def plot_distance_matrix(d_matrix):\n",
    "    sns.heatmap(d_matrix, cmap='viridis')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets were obtained from https://people.sc.fsu.edu/~jburkardt/datasets/tsp/tsp.html\n",
    "# feel free to test out the code with other datasets as long as they are in the same format (take a look into dataset/att48_d.txt for an example)\n",
    "file = \"dataset/att48_d.txt\" # change this to the path of the file you want to plot\n",
    "\n",
    "distance_matrix = load_distance_matrix(file)\n",
    "plot_matrix(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution $S$ may be represented as a permutation of cities, the first city being the starting city:\n",
    "$$\n",
    "S = \\set{C_{0},C_{1},C_{2},\\ldots,C_{n-1}}!\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_CITIES = distance_matrix[0].size\n",
    "\n",
    "def random_solution(num_cities: int):\n",
    "    return np.random.permutation(num_cities)\n",
    "\n",
    "solution = random_solution(NUMBER_OF_CITIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to define an evaluator to calculate the objective function $z$. In this case, the objective function is the total distance of the path:\n",
    "$$\n",
    "\\min{z} = \\sum_{i=0}^{n-2} D_{S_{i}S_{i+1}} + D_{S_{n-1}S_{0}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(solution, d_matrix):\n",
    "    total_distance = 0\n",
    "    for i in range(len(solution)):\n",
    "        total_distance += d_matrix[solution[i]][solution[(i+1)%len(solution)]]\n",
    "    total_distance += d_matrix[solution[-1]][solution[0]]\n",
    "    return total_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may test out the evaluator with the random solution.\n",
    "z_random = evaluate(solution, distance_matrix)\n",
    "print(\"Random solution distance: \", z_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Greedy Algorithm (Nearest Neighbour)\n",
    "Before delving into genetic algorithms, let's first implement a simple greedy algorithm to solve the TSP. The nearest neighbour algorithm is a simple and effective heuristic algorithm that starts from a random city and then selects the nearest unvisited city as the next city to visit. This process is repeated until all cities are visited. The algorithm is as follows:\n",
    "\n",
    "1. Start from a random city $C_{0}$.\n",
    "2. While there are unvisited cities:\n",
    "    1. Select the nearest unvisited city $C_{i}$ to the current city $C_{j}$.\n",
    "    2. Mark $C_{i}$ as visited.\n",
    "    3. Set $C_{j} = C_{i}$.\n",
    "3. Return to the starting city $C_{0}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_approach(d_matrix):\n",
    "    solution = [0]\n",
    "    visited = [False] * NUMBER_OF_CITIES\n",
    "    visited[0] = True\n",
    "    for _ in range(NUMBER_OF_CITIES - 1):\n",
    "        last_city = solution[-1]\n",
    "        best_neighbour = None\n",
    "        best_distance = float('inf')\n",
    "        for i in range(NUMBER_OF_CITIES):\n",
    "            if not visited[i] and d_matrix[last_city][i] < best_distance:\n",
    "                best_neighbour = i\n",
    "                best_distance = d_matrix[last_city][i]\n",
    "        solution.append(best_neighbour)\n",
    "        visited[best_neighbour] = True\n",
    "    return solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may test out the evaluator with the greedy solution.\n",
    "greedy_solution = greedy_approach(distance_matrix)\n",
    "z_greedy = evaluate(greedy_solution, distance_matrix)\n",
    "print(\"Random solution distance: \", z_random)\n",
    "print(\"Greedy solution distance: \", z_greedy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Genetic Algorithm\n",
    "Genetic algorithms are inspired by the process of natural selection. They are based on the idea of evolution, where the fittest individuals are selected for reproduction in order to produce offspring of the next generation. The algorithm follows these steps:\n",
    "\n",
    "1. **Initialization**: Create an initial population of individuals.\n",
    "2. **Evaluation**: Evaluate the fitness of each individual in the population.\n",
    "3. **Selection**: Select the fittest individuals to reproduce.\n",
    "4. **Crossover**: Create offspring by combining the genetic material of the selected individuals.\n",
    "5. **Mutation**: Introduce random changes in the offspring.\n",
    "6. **Replacement**: Replace the least fit individuals in the population with the offspring.\n",
    "7. **Termination**: Repeat steps 2-6 until a termination condition is met. (*)\n",
    "\n",
    "(*) Should there be no termination condition, the algorithm will run indefinitely. The termination condition can be a fixed number of generations, a fixed amount of time, or a convergence criterion. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Initialization\n",
    "The first step in the genetic algorithm is to create an initial population of individuals. Each individual represents a possible solution to the problem. In the case of the TSP, an individual is a permutation of the cities. The population size is a parameter that can be adjusted to balance the exploration-exploitation trade-off. A larger population size increases the diversity of the population but also increases the computational cost.\n",
    "\n",
    "In this implementation, we will generate a random population of individuals. Each individual is a permutation of the cities, starting from a random city. The population size is a parameter that can be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(population_size, num_cities):\n",
    "    return np.array([random_solution(num_cities) for _ in range(population_size)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to generate a population of random solutions.\n",
    "population = generate_population(population_size, NUMBER_OF_CITIES)\n",
    "print(\"Random population: \\n\", population)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evaluation\n",
    "The next step is to evaluate the fitness of each individual in the population. The fitness of an individual is determined by the objective function, which in this case is the total distance of the path. The lower the total distance, the higher the fitness of the individual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population, d_matrix):\n",
    "    return np.array([evaluate(solution, d_matrix) for solution in population])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Selection\n",
    "The selection step is where the fittest individuals are chosen to reproduce. There are several selection methods, such as roulette wheel selection, tournament selection, and rank-based selection. In this implementation, we will use roulette wheel selection, which selects individuals with a probability proportional to their fitness. This means that fitter individuals are more likely to be selected for reproduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_selection(population, fitness):\n",
    "    probabilities = fitness / fitness.sum()\n",
    "    return population[np.random.choice(np.arange(len(population)), p=probabilities)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Crossover\n",
    "The crossover step is where offspring are created by combining the genetic material of the selected individuals. There are several crossover methods, such as one-point crossover, two-point crossover, and uniform crossover. In this implementation, we will use ordered crossover, which preserves the order of the cities in the parents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered_crossover(parent1, parent2):\n",
    "    n = len(parent1)\n",
    "    i, j = np.random.choice(n, 2, replace=False)\n",
    "    i, j = min(i, j), max(i, j)\n",
    "    \n",
    "    child = -1 * np.ones(n)\n",
    "    child[i:j] = parent1[i:j]\n",
    "    \n",
    "    k = 0\n",
    "    for l in range(n):\n",
    "        if k == i:  # Skip the filled segment\n",
    "            k = j\n",
    "        if parent2[l] not in child:\n",
    "            child[k] = parent2[l]\n",
    "            k += 1\n",
    "            \n",
    "    return child\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Mutation\n",
    "The mutation step introduces random changes in the offspring to maintain genetic diversity in the population. There are several mutation methods, such as swap mutation, inversion mutation, and scramble mutation. In this implementation, we will use swap mutation, which swaps two cities in the offspring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_mutation(solution):\n",
    "    i, j = np.random.choice(len(solution), 2, replace=False)\n",
    "    solution[i], solution[j] = solution[j], solution[i]\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Replacement\n",
    "The replacement step is where the least fit individuals in the population are replaced by the offspring. There are several replacement methods, such as generational replacement, elitist replacement, and steady-state replacement. In this implementation, we will use generational replacement, where the entire population is replaced by the offspring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_worst(population, fitness, new_solution):\n",
    "    worst_idx = np.argmax(fitness)\n",
    "    population[worst_idx] = new_solution\n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Termination\n",
    "The termination step is where the algorithm stops when a termination condition is met. The termination condition can be a fixed number of generations, a fixed amount of time, or a convergence criterion. In this implementation, we will use a fixed number of generations as the termination condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(matrix, population_size, generations):\n",
    "    population = generate_population(population_size, NUMBER_OF_CITIES)\n",
    "    fitness = evaluate_population(population, matrix)\n",
    "    convergence = np.zeros(generations)\n",
    "    for i in range(generations):\n",
    "        parent1 = roulette_selection(population, fitness)\n",
    "        parent2 = roulette_selection(population, fitness)\n",
    "        child = ordered_crossover(parent1, parent2)\n",
    "        child = swap_mutation(child)\n",
    "\n",
    "        population = replace_worst(population, fitness, child)\n",
    "        fitness = evaluate_population(population, matrix)\n",
    "        \n",
    "        best_population_z = fitness.min()\n",
    "        convergence[i] = best_population_z\n",
    "        population_mean_z = fitness.mean()\n",
    "\n",
    "        print(f\"Generation: {i}, Best solution: {best_population_z}, Mean solution: {population_mean_z}\")\n",
    "    return population, fitness, convergence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 100 # change this to the desired population size\n",
    "n_of_generations = 10000 # change this to the desired number of generations\n",
    "\n",
    "population, fitness, convergence = genetic_algorithm(distance_matrix, population_size, n_of_generations)\n",
    "print(\"Final population: \\n\", population)\n",
    "print(\"Final fitness: \\n\", fitness)\n",
    "\n",
    "best_solution = population[np.argmin(fitness)]\n",
    "z_best = evaluate(best_solution, distance_matrix)\n",
    "print(\"Best solution: \\n\", best_solution)\n",
    "print(\"Best solution distance: \", z_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "We have seen too much theory, let's visualize the algorithm in action. We have already visualized a matrix heatmap, now we will visualize more details about the problem, that will give us a retrospective of the algorithm.\n",
    "1. **Path Visualization**: We will visualize the path of the salesman on the map.\n",
    "2. **Convergence Visualization**: We will visualize the convergence of the algorithm over generations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Path Visualization\n",
    "We will visualize the path of the salesman on the map. For this we will use XY coordinates of the cities. We will plot the cities and the path connecting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the XY coordinates of the cities\n",
    "def load_coordinates(filename):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "    n = len(lines)\n",
    "    coordinates = np.zeros((n, 2))\n",
    "    for i, line in enumerate(lines):\n",
    "        coordinates[i] = list(map(float, line.split()))\n",
    "    return coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to test out the code with other datasets as long as they are in the same format (take a look into dataset/att48_xy.txt for an example)\n",
    "file = \"dataset/att48_xy.txt\" # change this to the path of the file you want to plot\n",
    "coordinates = load_coordinates(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot solutions with a tag of the city number\n",
    "def plot_solution(coordinates, solution):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title(\"TSP Genetic Alg. solution\")\n",
    "    plt.scatter(coordinates[:, 0], coordinates[:, 1], color='red')\n",
    "    for i in range(len(solution)):\n",
    "        city1 = solution[i]\n",
    "        city2 = solution[(i+1)%len(solution)]\n",
    "        plt.plot([coordinates[city1][0], coordinates[city2][0]], [coordinates[city1][1], coordinates[city2][1]], color='blue')\n",
    "        plt.text(coordinates[city1][0], coordinates[city1][1], str(i))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_solution(coordinates, best_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Convergence Visualization\n",
    "We will visualize the convergence of the algorithm over generations. The convergence plot shows the best fitness value found so far in each generation. The goal is to see how the fitness value improves over time and whether the algorithm is converging to a good solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_convergence(convergence):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(convergence)\n",
    "    plt.title(\"Population Best Solution Convergence\")\n",
    "    plt.xlabel(\"Generation\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_convergence(convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "In this notebook, we have implemented a genetic algorithm to solve the travelling salesman problem. We have seen how the algorithm works and how it can be applied to solve combinatorial optimization problems. We have also visualized the algorithm in action to gain a better understanding of how it works. \n",
    "\n",
    "This project was inspired by Operations Research course at my university. I hope you have enjoyed it and learned something new. If you have any questions or feedback, feel free to reach out to me. Thank you for reading!\n",
    "\n",
    "## 6. FAQ\n",
    "Why is the greedy algorithm faster than the genetic algorithm? \n",
    "The greedy algorithm is faster than the genetic algorithm because it is a simple heuristic algorithm that does not require the computational overhead of genetic algorithms. The greedy algorithm is also more efficient in terms of memory usage, as it does not require the storage of a population of individuals. However, the greedy algorithm may not always find the optimal solution, as it makes locally optimal choices that may not lead to a globally optimal solution. In contrast, the genetic algorithm is a more robust optimization technique that can find good solutions to complex problems, but it requires more computational resources and time to converge to a solution.\n",
    "\n",
    "Why is the solution of the greedy algorithm better than the genetic algorithm?\n",
    "The solution of the greedy algorithm may be better than the genetic algorithm in some cases because the greedy algorithm makes locally optimal choices that may lead to a better solution in the short term. However, the greedy algorithm may get stuck in a local minimum and fail to find the globally optimal solution. In contrast, the genetic algorithm explores a larger search space and can find better solutions in the long term by combining genetic material from different individuals. Therefore we may need to run the genetic algorithm for more generations to find a better solution.\n",
    "\n",
    "Why is TSP important?\n",
    "The travelling salesman problem (TSP) is an important problem in combinatorial optimization and operations research. It has applications in logistics, transportation, and supply chain management, where it is used to optimize the routing of vehicles and delivery schedules. The TSP is also a classic problem in computer science and mathematics, and it has been studied extensively in the fields of optimization and algorithms. The TSP is a challenging problem because it is NP-hard, which means that it is difficult to solve in polynomial time. But as we have seen in this notebook, heuristic algorithms like the genetic algorithm can be used to find good solutions to the TSP in a reasonable time.\n",
    "\n",
    "## 7. References\n",
    "1. [Wikipedia - Travelling Salesman Problem](https://en.wikipedia.org/wiki/Travelling_salesman_problem)\n",
    "2. [Wikipedia - Genetic Algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm)\n",
    "3. [Genetic Algorithm for the Travelling Salesman Problem](https://towardsdatascience.com/genetic-algorithm-for-the-travelling-salesman-problem-69a052d8b15e)\n",
    "4. Dataset: [TSP dataset](https://people.sc.fsu.edu/~jburkardt/datasets/tsp/tsp.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
